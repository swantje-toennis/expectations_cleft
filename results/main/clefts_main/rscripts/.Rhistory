# plot
ggplot(means1, aes(x=cond_c, y=Mean,color=cond_q,fill=cond_q)) +
#geom_point(stroke=.5,size=3,color="black") +
geom_text(aes(label=cond_q,alpha = alpha,fontface=font),size=size) +
theme(legend.position="none") +
scale_shape_manual(values=c(21)) +
#scale_fill_manual(values=c("#56B4E9","#E69F00"),labels=c("0","2"),name="Distance to PQ-raising sentence",guide = guide_legend(reverse = TRUE) ) +
#geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.15) +
#theme(legend.position = "top", legend.text=element_text(size=12)) +
labs(x='Context condition', y='Mean question expectedness') +
scale_y_continuous(limits = c(0,100),breaks = c(0,25,50,75,100),
labels= c("0","25","50","75","100")) +
scale_color_manual(values=cbPalette) +
scale_fill_manual(values=cbPalette)
ggsave("../graphs/main_results_norming.pdf",height=2.5,width=2.5)
table(data$cond_q)
levels(data$cond_c)
data$cond_c <- relevel(data$cond_c, ref = "3")
table(data$cond_q)
# calculate mean for pq1 by condition
means1 <- data %>%
group_by(cond_c, cond_q) %>%
summarize(Mean=mean(expec),CILow=ci.low(expec),CIHigh=ci.high(expec)) %>%
ungroup() %>%
mutate(YMin=Mean-CILow,YMax=Mean+CIHigh)
means1
View(means1)
# color-blind-friendly palette
cbPalette <- c("#56B4E9","red","#56B4E9","#56B4E9","#56B4E9")
#"#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7","darkgrey") # c("#999999",
# grey color palette
#cbPalette <- c("grey20","grey10","grey20","grey20","grey20")
# set alpha
alpha <- ifelse(means1$cond_q == "Q1", 1, 1)
# set size and font
size <- ifelse(means1$cond_q == "Q1", 6, 5)
font <- ifelse(means1$cond_q == "Q1", 2, 1)
levels(means1$cond_q)
# plot
ggplot(means1, aes(x=cond_c, y=Mean,color=cond_q,fill=cond_q)) +
#geom_point(stroke=.5,size=3,color="black") +
geom_text(aes(label=cond_q,alpha = alpha,fontface=font),size=size) +
theme(legend.position="none") +
scale_shape_manual(values=c(21)) +
#scale_fill_manual(values=c("#56B4E9","#E69F00"),labels=c("0","2"),name="Distance to PQ-raising sentence",guide = guide_legend(reverse = TRUE) ) +
#geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.15) +
#theme(legend.position = "top", legend.text=element_text(size=12)) +
labs(x='Context condition', y='Mean question expectedness') +
scale_y_continuous(limits = c(0,100),breaks = c(0,25,50,75,100),
labels= c("0","25","50","75","100")) +
scale_color_manual(values=cbPalette) +
scale_fill_manual(values=cbPalette)
ggsave("../graphs/main_results_norming.pdf",height=2.5,width=2.5)
get_pvalues(model5)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
library(readxl)
library(readr)
library(ggplot2)
library(ggpubr)
library(plyr)
library(dplyr)
library(ez)
library(lme4)
library(languageR)
library(car)
library(MASS)
library(fitdistrplus)
library(ordinal)
library(nlme)
library(logspline)
library(gplots)
library(stringr)
library(tidyr)
library(broom)
library(tidyselect)
library(tidyverse)
# For get_pvalues: load remote package from GitHub server
install.packages("remotes")
remotes::install_github("dmirman/gazer")
library(gazer) #get pvalues
########################################################
source("C:/Arbeit/R statistics/mer-utils.r")
source("C:/Arbeit/R statistics/regression-utils.r")
source("C:/Arbeit/R statistics/diagnostic_fcns.r")
source("C:/Arbeit/R statistics/boot_glmm.r")
source("C:/Arbeit/R statistics/helpers.r")
#### load data ###########
data_t <- read.csv("../data/preprocessed_data/data_t.csv", sep = ";")
nrow(data) #6240
#### Interpret judgment as numbers and context, tendency, condition A, condition B and list as a factors #####
data_t$judgment<-as.numeric(data_t$judgment)
data_t$cond_c<-as.factor(data_t$cond_c)
data_t$condA<-as.factor(data_t$condA)
data_t$condB<-as.factor(data_t$condB)
data_t$list <- as.factor(data_t$list)
data_t$tendency <- as.factor(data_t$tendency)
str(data_t)
##### show the mean and standard deviation for the two expectedness conditions ##########
data_t %>% group_by(cond_c) %>%
summarize(M = mean(judgment), SD = sd(judgment))
#cond_c     M    SD
# c1      6.63  65.5
# c3     32.3   55.0
#######################
####   Models ----
######################
# Stepwise comparison of a more specified model to a less specified model
# Used anova to compare two models
#### model 1 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') and list as fixed effects interaction
model1 <- lmer(judgment ~ cond_c * list + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
#### model 2 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') and list as fixed effects
model2 <- lmer(judgment ~ cond_c + list + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
# comparison of model 1 and 2
anova(model1,model2) # not significant, drop interaction
#### model 3 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') as fixed effects (whithout list)
model3 <- lmer(judgment ~ cond_c + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
# comparison of model 2 and 3
anova(model2,model3) # not significant, drop list as fixed effect
#### model 4 -- With varying intercepts and slopes for participant ('id')
# and varying intercepts for context item ('target_no'),
# context condition ('cond_c') as fixed effects (whithout list)
model4 <- lmer(judgment ~ cond_c + (1 + cond_c|id) + (1|target_no), data = data_t)
# not singular
# comparison of model 3 and 4
anova(model3,model4) # not significant, drop item slopes
#### model 5 -- With varying intercepts and slopes for participant ('id'),
# context condition ('cond_c') as fixed effects (whithout list)
model5 <- lmer(judgment ~ cond_c + (1 + cond_c|id), data = data_t)
# not singular
# comparison of model 4 and 5
anova(model4,model5) # not significant, drop item as random effect
#### model 6 -- With varying intercepts for participant ('id') and
# context condition ('cond_c') as fixed effects (whithout list)
model6 <- lmer(judgment ~ cond_c + (1|id), data = data_t)
# not singular
# comparison of model 5 and 6
anova(model5,model6) # significant, keep by participant varying slopes
#### pick model 5!  ##########
summary(model5)
get_pvalues(model5)
install.packages("remotes")
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
library(readxl)
library(readr)
library(ggplot2)
library(ggpubr)
library(plyr)
library(dplyr)
library(ez)
library(lme4)
library(languageR)
library(car)
library(MASS)
library(fitdistrplus)
library(ordinal)
library(nlme)
library(logspline)
library(gplots)
library(stringr)
library(tidyr)
library(broom)
library(tidyselect)
library(tidyverse)
# For get_pvalues: load remote package from GitHub server
install.packages("remotes")
remotes::install_github("dmirman/gazer")
library(gazer) #get pvalues
########################################################
source("C:/Arbeit/R statistics/mer-utils.r")
source("C:/Arbeit/R statistics/regression-utils.r")
source("C:/Arbeit/R statistics/diagnostic_fcns.r")
source("C:/Arbeit/R statistics/boot_glmm.r")
source("C:/Arbeit/R statistics/helpers.r")
#### load data ###########
data_t <- read.csv("../data/preprocessed_data/data_t.csv", sep = ";")
nrow(data) #6240
#### Interpret judgment as numbers and context, tendency, condition A, condition B and list as a factors #####
data_t$judgment<-as.numeric(data_t$judgment)
data_t$cond_c<-as.factor(data_t$cond_c)
data_t$condA<-as.factor(data_t$condA)
data_t$condB<-as.factor(data_t$condB)
data_t$list <- as.factor(data_t$list)
data_t$tendency <- as.factor(data_t$tendency)
str(data_t)
##### show the mean and standard deviation for the two expectedness conditions ##########
data_t %>% group_by(cond_c) %>%
summarize(M = mean(judgment), SD = sd(judgment))
#cond_c     M    SD
# c1      6.63  65.5
# c3     32.3   55.0
#######################
####   Models ----
######################
# Stepwise comparison of a more specified model to a less specified model
# Used anova to compare two models
#### model 1 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') and list as fixed effects interaction
model1 <- lmer(judgment ~ cond_c * list + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
#### model 2 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') and list as fixed effects
model2 <- lmer(judgment ~ cond_c + list + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
# comparison of model 1 and 2
anova(model1,model2) # not significant, drop interaction
#### model 3 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') as fixed effects (whithout list)
model3 <- lmer(judgment ~ cond_c + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
# comparison of model 2 and 3
anova(model2,model3) # not significant, drop list as fixed effect
#### model 4 -- With varying intercepts and slopes for participant ('id')
# and varying intercepts for context item ('target_no'),
# context condition ('cond_c') as fixed effects (whithout list)
model4 <- lmer(judgment ~ cond_c + (1 + cond_c|id) + (1|target_no), data = data_t)
# not singular
# comparison of model 3 and 4
anova(model3,model4) # not significant, drop item slopes
#### model 5 -- With varying intercepts and slopes for participant ('id'),
# context condition ('cond_c') as fixed effects (whithout list)
model5 <- lmer(judgment ~ cond_c + (1 + cond_c|id), data = data_t)
# not singular
# comparison of model 4 and 5
anova(model4,model5) # not significant, drop item as random effect
#### model 6 -- With varying intercepts for participant ('id') and
# context condition ('cond_c') as fixed effects (whithout list)
model6 <- lmer(judgment ~ cond_c + (1|id), data = data_t)
# not singular
# comparison of model 5 and 6
anova(model5,model6) # significant, keep by participant varying slopes
#### pick model 5!  ##########
summary(model5)
get_pvalues(model5)
install.packages("remotes")
########################################################
source("C:/Arbeit/R statistics/mer-utils.r")
source("C:/Arbeit/R statistics/regression-utils.r")
source("C:/Arbeit/R statistics/diagnostic_fcns.r")
source("C:/Arbeit/R statistics/boot_glmm.r")
source("C:/Arbeit/R statistics/helpers.r")
#### load data ###########
data_t <- read.csv("../data/preprocessed_data/data_t.csv", sep = ";")
nrow(data) #6240
#### Interpret judgment as numbers and context, tendency, condition A, condition B and list as a factors #####
data_t$judgment<-as.numeric(data_t$judgment)
data_t$cond_c<-as.factor(data_t$cond_c)
data_t$condA<-as.factor(data_t$condA)
data_t$condB<-as.factor(data_t$condB)
data_t$list <- as.factor(data_t$list)
data_t$tendency <- as.factor(data_t$tendency)
str(data_t)
##### show the mean and standard deviation for the two expectedness conditions ##########
data_t %>% group_by(cond_c) %>%
summarize(M = mean(judgment), SD = sd(judgment))
#cond_c     M    SD
# c1      6.63  65.5
# c3     32.3   55.0
#######################
####   Models ----
######################
# Stepwise comparison of a more specified model to a less specified model
# Used anova to compare two models
#### model 1 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') and list as fixed effects interaction
model1 <- lmer(judgment ~ cond_c * list + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
#### model 2 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') and list as fixed effects
model2 <- lmer(judgment ~ cond_c + list + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
# comparison of model 1 and 2
anova(model1,model2) # not significant, drop interaction
#### model 3 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') as fixed effects (whithout list)
model3 <- lmer(judgment ~ cond_c + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
# comparison of model 2 and 3
anova(model2,model3) # not significant, drop list as fixed effect
#### model 4 -- With varying intercepts and slopes for participant ('id')
# and varying intercepts for context item ('target_no'),
# context condition ('cond_c') as fixed effects (whithout list)
model4 <- lmer(judgment ~ cond_c + (1 + cond_c|id) + (1|target_no), data = data_t)
# not singular
# comparison of model 3 and 4
anova(model3,model4) # not significant, drop item slopes
#### model 5 -- With varying intercepts and slopes for participant ('id'),
# context condition ('cond_c') as fixed effects (whithout list)
model5 <- lmer(judgment ~ cond_c + (1 + cond_c|id), data = data_t)
# not singular
# comparison of model 4 and 5
anova(model4,model5) # not significant, drop item as random effect
#### model 6 -- With varying intercepts for participant ('id') and
# context condition ('cond_c') as fixed effects (whithout list)
model6 <- lmer(judgment ~ cond_c + (1|id), data = data_t)
# not singular
# comparison of model 5 and 6
anova(model5,model6) # significant, keep by participant varying slopes
#### pick model 5!  ##########
summary(model5)
get_pvalues(model5)
#### model 5 -- With varying intercepts and slopes for participant ('id'),
# context condition ('cond_c') as fixed effects (whithout list)
model5 <- lmer(judgment ~ cond_c + (1 + cond_c|id), data = data_t)
#### load data ###########
data_t <- read.csv("../data/preprocessed_data/data_t.csv", sep = ";")
nrow(data) #6240
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
library(readxl)
library(readr)
library(ggplot2)
library(ggpubr)
library(plyr)
library(dplyr)
library(ez)
library(lme4)
library(languageR)
library(car)
library(MASS)
library(fitdistrplus)
library(ordinal)
library(nlme)
library(logspline)
library(gplots)
library(stringr)
library(tidyr)
library(broom)
library(tidyselect)
library(tidyverse)
# For get_pvalues: load remote package from GitHub server
install.packages("remotes")
remotes::install_github("dmirman/gazer")
library(gazer) #get pvalues
install.packages("remotes")
source("C:/Arbeit/R statistics/mer-utils.r")
source("C:/Arbeit/R statistics/regression-utils.r")
source("C:/Arbeit/R statistics/diagnostic_fcns.r")
source("C:/Arbeit/R statistics/boot_glmm.r")
source("C:/Arbeit/R statistics/helpers.r")
#### load data ###########
data_t <- read.csv("../data/preprocessed_data/data_t.csv", sep = ";")
source("C:/Arbeit/R statistics/mer-utils.r")
source("C:/Arbeit/R statistics/regression-utils.r")
source("C:/Arbeit/R statistics/diagnostic_fcns.r")
source("C:/Arbeit/R statistics/boot_glmm.r")
source("C:/Arbeit/R statistics/helpers.r")
#### load data ###########
data_t <- read.csv("../data/preprocessed_data/data_t.csv", sep = ";")
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
data_t <- read.csv("../data/preprocessed_data/data_t.csv", sep = ";")
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
library(readxl)
library(readr)
library(ggplot2)
library(ggpubr)
library(plyr)
library(dplyr)
library(ez)
library(lme4)
library(languageR)
library(car)
library(MASS)
library(fitdistrplus)
library(ordinal)
library(nlme)
library(logspline)
library(gplots)
library(stringr)
library(tidyr)
library(broom)
library(tidyselect)
library(tidyverse)
########################################################
source("C:/Arbeit/R statistics/mer-utils.r")
source("C:/Arbeit/R statistics/regression-utils.r")
source("C:/Arbeit/R statistics/diagnostic_fcns.r")
source("C:/Arbeit/R statistics/boot_glmm.r")
source("C:/Arbeit/R statistics/helpers.r")
#### load data ###########
data_t <- read.csv("../data/preprocessed_data/data_t.csv", sep = ";")
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source('helpers.R')
# load required packages
library(tidyverse)
# set theme for figures
theme_set(theme_bw())
# load data
data_t <- read.csv("../data/data_t.csv", sep = ";")
nrow(data_t) #372
summary(data_t)
# load data
data_t <- read.csv("../data/preprocessed_data/data_t.csv", sep = ";")
data_t <- read.csv("../results/data/preprocessed_data/data_t.csv", sep = ";")
View(data_t)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
library(readxl)
library(readr)
library(ggplot2)
library(ggpubr)
library(plyr)
library(dplyr)
library(ez)
library(lme4)
library(languageR)
library(car)
library(MASS)
library(fitdistrplus)
library(ordinal)
library(nlme)
library(logspline)
library(gplots)
library(stringr)
library(tidyr)
library(broom)
library(tidyselect)
library(tidyverse)
# For get_pvalues: load remote package from GitHub server
install.packages("remotes")
remotes::install_github("dmirman/gazer")
library(gazer) #get pvalues
install.packages("remotes")
########################################################
source("C:/Arbeit/R statistics/mer-utils.r")
source("C:/Arbeit/R statistics/regression-utils.r")
source("C:/Arbeit/R statistics/diagnostic_fcns.r")
source("C:/Arbeit/R statistics/boot_glmm.r")
source("C:/Arbeit/R statistics/helpers.r")
#### load data ###########
read.csv("../results/preprocessed_data/data_t.csv", sep = ";")
nrow(data) #6240
data_t <- read.csv("../results/preprocessed_data/data_t.csv", sep = ";")
nrow(data_t) #6240
#### Interpret judgment as numbers and context, tendency, condition A, condition B and list as a factors #####
data_t$judgment<-as.numeric(data_t$judgment)
data_t$cond_c<-as.factor(data_t$cond_c)
data_t$condA<-as.factor(data_t$condA)
data_t$condB<-as.factor(data_t$condB)
data_t$list <- as.factor(data_t$list)
data_t$tendency <- as.factor(data_t$tendency)
str(data_t)
##### show the mean and standard deviation for the two expectedness conditions ##########
data_t %>% group_by(cond_c) %>%
summarize(M = mean(judgment), SD = sd(judgment))
#cond_c     M    SD
# c1      6.63  65.5
# c3     32.3   55.0
model1 <- lmer(judgment ~ cond_c * list + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
#### model 2 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') and list as fixed effects
model2 <- lmer(judgment ~ cond_c + list + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
# comparison of model 1 and 2
anova(model1,model2) # not significant, drop interaction
#### model 3 -- With varying intercepts and slopes for participant ('id')
# and context item ('target_no'),
# context condition ('cond_c') as fixed effects (whithout list)
model3 <- lmer(judgment ~ cond_c + (1 + cond_c|id) + (1 + cond_c|target_no), data = data_t)
#singular
# comparison of model 2 and 3
anova(model2,model3) # not significant, drop list as fixed effect
#### model 4 -- With varying intercepts and slopes for participant ('id')
# and varying intercepts for context item ('target_no'),
# context condition ('cond_c') as fixed effects (whithout list)
model4 <- lmer(judgment ~ cond_c + (1 + cond_c|id) + (1|target_no), data = data_t)
# not singular
# comparison of model 3 and 4
anova(model3,model4) # not significant, drop item slopes
#### model 5 -- With varying intercepts and slopes for participant ('id'),
# context condition ('cond_c') as fixed effects (whithout list)
model5 <- lmer(judgment ~ cond_c + (1 + cond_c|id), data = data_t)
# not singular
# comparison of model 4 and 5
anova(model4,model5) # not significant, drop item as random effect
#### model 6 -- With varying intercepts for participant ('id') and
# context condition ('cond_c') as fixed effects (whithout list)
model6 <- lmer(judgment ~ cond_c + (1|id), data = data_t)
# not singular
# comparison of model 5 and 6
anova(model5,model6) # significant, keep by participant varying slopes
#### pick model 5!  ##########
summary(model5)
get_pvalues(model5)
